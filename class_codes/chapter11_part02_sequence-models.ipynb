{"cells":[{"cell_type":"markdown","metadata":{"id":"DnPMM9BioMYP"},"source":["This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n","\n","**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n","\n","This notebook was generated for TensorFlow 2.6."]},{"cell_type":"markdown","metadata":{"id":"Jnsvm9EfoMYU"},"source":["### Processing words as a sequence: The sequence model approach"]},{"cell_type":"markdown","metadata":{"id":"ygXq70SdoMYW"},"source":["#### A first practical example"]},{"cell_type":"markdown","metadata":{"id":"rdJPB-QloMYX"},"source":["**Downloading the data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0RMOIN7oMYX","executionInfo":{"status":"ok","timestamp":1698123950814,"user_tz":-300,"elapsed":10439,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"outputId":"e42c8fc3-6b53-42f8-bb8e-e6ecacdb87db"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  65.0M      0  0:00:01  0:00:01 --:--:-- 65.0M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"]},{"cell_type":"markdown","metadata":{"id":"X4vP0TxIoMYY"},"source":["**Preparing the data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llxm21bGoMYZ","executionInfo":{"status":"ok","timestamp":1698123987680,"user_tz":-300,"elapsed":12620,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"outputId":"8e8c1c88-a87b-4d69-e848-4700f4073188"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["import os, pathlib, shutil, random\n","from tensorflow import keras\n","batch_size = 32\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)"]},{"cell_type":"markdown","metadata":{"id":"qMi3KhGtoMYa"},"source":["**Preparing integer sequence datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYYqrP1AoMYa"},"outputs":[],"source":["from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"]},{"cell_type":"code","source":["text_vectorization.get_vocabulary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rY0LUhKhpHoh","executionInfo":{"status":"ok","timestamp":1698124004803,"user_tz":-300,"elapsed":471,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"outputId":"90d82bbd-5f47-495d-e9d7-959423fecc4f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'the',\n"," 'a',\n"," 'and',\n"," 'of',\n"," 'to',\n"," 'is',\n"," 'in',\n"," 'it',\n"," 'i',\n"," 'this',\n"," 'that',\n"," 'br',\n"," 'was',\n"," 'as',\n"," 'with',\n"," 'for',\n"," 'movie',\n"," 'but',\n"," 'film',\n"," 'on',\n"," 'not',\n"," 'you',\n"," 'are',\n"," 'his',\n"," 'have',\n"," 'he',\n"," 'be',\n"," 'one',\n"," 'its',\n"," 'at',\n"," 'all',\n"," 'by',\n"," 'an',\n"," 'they',\n"," 'who',\n"," 'from',\n"," 'so',\n"," 'like',\n"," 'her',\n"," 'or',\n"," 'just',\n"," 'about',\n"," 'has',\n"," 'if',\n"," 'out',\n"," 'some',\n"," 'there',\n"," 'what',\n"," 'good',\n"," 'more',\n"," 'very',\n"," 'when',\n"," 'my',\n"," 'even',\n"," 'she',\n"," 'no',\n"," 'up',\n"," 'would',\n"," 'which',\n"," 'only',\n"," 'time',\n"," 'really',\n"," 'story',\n"," 'their',\n"," 'see',\n"," 'had',\n"," 'were',\n"," 'can',\n"," 'me',\n"," 'than',\n"," 'we',\n"," 'much',\n"," 'well',\n"," 'been',\n"," 'get',\n"," 'also',\n"," 'into',\n"," 'will',\n"," 'because',\n"," 'great',\n"," 'do',\n"," 'people',\n"," 'bad',\n"," 'other',\n"," 'first',\n"," 'most',\n"," 'how',\n"," 'dont',\n"," 'him',\n"," 'made',\n"," 'then',\n"," 'films',\n"," 'movies',\n"," 'make',\n"," 'any',\n"," 'could',\n"," 'them',\n"," 'way',\n"," 'too',\n"," 'after',\n"," 'characters',\n"," 'think',\n"," 'watch',\n"," 'many',\n"," 'two',\n"," 'being',\n"," 'character',\n"," 'never',\n"," 'seen',\n"," 'little',\n"," 'where',\n"," 'plot',\n"," 'best',\n"," 'acting',\n"," 'love',\n"," 'did',\n"," 'know',\n"," 'show',\n"," 'does',\n"," 'ever',\n"," 'life',\n"," 'your',\n"," 'better',\n"," 'still',\n"," 'off',\n"," 'over',\n"," 'end',\n"," 'these',\n"," 'say',\n"," 'here',\n"," 'while',\n"," 'scene',\n"," 'man',\n"," 'why',\n"," 'such',\n"," 'scenes',\n"," 'go',\n"," 'should',\n"," 'something',\n"," 'through',\n"," 'im',\n"," 'back',\n"," 'those',\n"," 'doesnt',\n"," 'watching',\n"," 'years',\n"," 'real',\n"," 'now',\n"," 'though',\n"," 'thing',\n"," 'actors',\n"," 'didnt',\n"," 'before',\n"," 'another',\n"," 'actually',\n"," 'nothing',\n"," 'new',\n"," 'makes',\n"," 'work',\n"," 'few',\n"," 'funny',\n"," 'find',\n"," 'going',\n"," 'look',\n"," 'old',\n"," 'same',\n"," 'part',\n"," 'every',\n"," 'lot',\n"," 'us',\n"," 'again',\n"," 'director',\n"," 'quite',\n"," 'cant',\n"," 'thats',\n"," 'want',\n"," 'cast',\n"," 'young',\n"," 'things',\n"," 'seems',\n"," 'pretty',\n"," 'got',\n"," 'around',\n"," 'fact',\n"," 'world',\n"," 'however',\n"," 'take',\n"," 'both',\n"," 'down',\n"," 'enough',\n"," 'big',\n"," 'may',\n"," 'between',\n"," 'horror',\n"," 'own',\n"," 'ive',\n"," 'give',\n"," 'without',\n"," 'thought',\n"," 'original',\n"," 'gets',\n"," 'always',\n"," 'isnt',\n"," 'series',\n"," 'long',\n"," 'right',\n"," 'saw',\n"," 'come',\n"," 'times',\n"," 'role',\n"," 'action',\n"," 'point',\n"," 'theres',\n"," 'family',\n"," 'least',\n"," 'almost',\n"," 'interesting',\n"," 'must',\n"," 'comedy',\n"," 'whole',\n"," 'bit',\n"," 'music',\n"," 'done',\n"," 'script',\n"," 'anything',\n"," 'last',\n"," 'feel',\n"," 'minutes',\n"," 'since',\n"," 'hes',\n"," 'performance',\n"," 'probably',\n"," 'guy',\n"," 'far',\n"," 'might',\n"," 'am',\n"," 'rather',\n"," 'yet',\n"," 'kind',\n"," 'worst',\n"," 'away',\n"," 'sure',\n"," 'girl',\n"," 'tv',\n"," 'having',\n"," 'woman',\n"," 'making',\n"," 'each',\n"," 'fun',\n"," 'played',\n"," 'found',\n"," 'anyone',\n"," 'believe',\n"," 'although',\n"," 'our',\n"," 'comes',\n"," 'trying',\n"," 'course',\n"," 'hard',\n"," 'especially',\n"," 'day',\n"," 'shows',\n"," 'looks',\n"," 'goes',\n"," 'different',\n"," 'put',\n"," 'wasnt',\n"," 'sense',\n"," 'maybe',\n"," 'place',\n"," 'set',\n"," 'once',\n"," 'reason',\n"," 'everything',\n"," 'main',\n"," 'true',\n"," 'worth',\n"," 'plays',\n"," 'looking',\n"," 'three',\n"," 'money',\n"," 'ending',\n"," '2',\n"," 'seem',\n"," 'beautiful',\n"," 'john',\n"," 'book',\n"," 'someone',\n"," 'actor',\n"," 'watched',\n"," 'job',\n"," 'screen',\n"," 'takes',\n"," 'instead',\n"," 'together',\n"," 'during',\n"," 'play',\n"," 'later',\n"," 'effects',\n"," '10',\n"," 'said',\n"," 'dvd',\n"," 'himself',\n"," 'special',\n"," 'everyone',\n"," 'version',\n"," 'left',\n"," 'seeing',\n"," 'audience',\n"," 'night',\n"," 'excellent',\n"," 'american',\n"," 'idea',\n"," 'house',\n"," 'nice',\n"," 'youre',\n"," 'wife',\n"," 'simply',\n"," 'high',\n"," 'shot',\n"," 'black',\n"," 'star',\n"," 'read',\n"," 'less',\n"," 'second',\n"," 'war',\n"," 'father',\n"," 'else',\n"," 'fan',\n"," 'help',\n"," 'given',\n"," 'used',\n"," 'kids',\n"," 'poor',\n"," 'try',\n"," 'completely',\n"," 'need',\n"," 'classic',\n"," 'death',\n"," 'men',\n"," 'use',\n"," 'short',\n"," 'friends',\n"," 'enjoy',\n"," 'either',\n"," 'until',\n"," 'rest',\n"," 'mind',\n"," 'year',\n"," 'performances',\n"," 'home',\n"," 'hollywood',\n"," 'truly',\n"," 'boring',\n"," 'production',\n"," 'along',\n"," 'couple',\n"," 'full',\n"," 'dead',\n"," 'remember',\n"," 'recommend',\n"," 'next',\n"," 'wrong',\n"," 'half',\n"," 'tell',\n"," 'perhaps',\n"," 'came',\n"," 'understand',\n"," 'women',\n"," 'wonderful',\n"," 'stupid',\n"," 'let',\n"," 'start',\n"," 'keep',\n"," 'camera',\n"," 'awful',\n"," 'others',\n"," 'line',\n"," 'small',\n"," 'moments',\n"," 'getting',\n"," 'episode',\n"," 'often',\n"," 'playing',\n"," 'sex',\n"," 'gives',\n"," 'early',\n"," 'terrible',\n"," 'mean',\n"," 'definitely',\n"," 'stars',\n"," 'become',\n"," 'lines',\n"," 'name',\n"," 'doing',\n"," 'finally',\n"," 'video',\n"," 'school',\n"," 'dialogue',\n"," 'piece',\n"," 'face',\n"," 'human',\n"," 'felt',\n"," 'itself',\n"," 'couldnt',\n"," 'case',\n"," 'yes',\n"," 'absolutely',\n"," 'lost',\n"," 'perfect',\n"," 'supposed',\n"," 'against',\n"," 'title',\n"," 'liked',\n"," 'top',\n"," 'written',\n"," 'person',\n"," 'entire',\n"," 'certainly',\n"," 'overall',\n"," 'waste',\n"," 'picture',\n"," 'sort',\n"," 'shes',\n"," 'live',\n"," 'style',\n"," 'evil',\n"," 'went',\n"," 'problem',\n"," 'several',\n"," 'head',\n"," 'hope',\n"," 'cinema',\n"," 'worse',\n"," 'loved',\n"," 'entertaining',\n"," 'budget',\n"," 'id',\n"," '3',\n"," 'boy',\n"," 'beginning',\n"," 'already',\n"," '\\x96',\n"," 'despite',\n"," 'becomes',\n"," 'mr',\n"," 'unfortunately',\n"," 'fans',\n"," 'throughout',\n"," 'based',\n"," 'mother',\n"," 'killer',\n"," 'dark',\n"," 'care',\n"," 'white',\n"," 'seemed',\n"," 'wanted',\n"," 'example',\n"," 'direction',\n"," 'guys',\n"," 'friend',\n"," 'final',\n"," 'lives',\n"," 'oh',\n"," 'youll',\n"," 'children',\n"," 'fine',\n"," 'totally',\n"," '1',\n"," 'wants',\n"," 'lead',\n"," 'wont',\n"," 'drama',\n"," 'turn',\n"," 'called',\n"," 'history',\n"," 'guess',\n"," 'amazing',\n"," 'sound',\n"," 'humor',\n"," 'laugh',\n"," 'girls',\n"," 'works',\n"," 'son',\n"," 'past',\n"," 'enjoyed',\n"," 'behind',\n"," 'tries',\n"," 'writing',\n"," 'low',\n"," 'under',\n"," 'turns',\n"," 'michael',\n"," 'game',\n"," 'gave',\n"," 'favorite',\n"," 'able',\n"," 'quality',\n"," 'starts',\n"," 'act',\n"," 'sometimes',\n"," 'kill',\n"," 'days',\n"," 'theyre',\n"," 'side',\n"," 'eyes',\n"," 'viewer',\n"," 'town',\n"," 'child',\n"," 'expect',\n"," 'flick',\n"," 'heart',\n"," 'art',\n"," 'soon',\n"," 'thinking',\n"," 'obviously',\n"," 'parts',\n"," 'themselves',\n"," 'genre',\n"," 'brilliant',\n"," 'ones',\n"," 'run',\n"," 'fight',\n"," 'late',\n"," 'actress',\n"," 'ill',\n"," 'directed',\n"," 'highly',\n"," 'stories',\n"," 'feeling',\n"," 'car',\n"," 'cannot',\n"," 'except',\n"," 'horrible',\n"," 'decent',\n"," 'took',\n"," 'hand',\n"," 'myself',\n"," 'leave',\n"," 'blood',\n"," 'close',\n"," 'says',\n"," 'city',\n"," 'kid',\n"," 'heard',\n"," 'killed',\n"," 'stuff',\n"," 'wouldnt',\n"," 'particularly',\n"," 'police',\n"," 'matter',\n"," 'extremely',\n"," 'moment',\n"," 'james',\n"," 'hour',\n"," 'strong',\n"," 'lack',\n"," 'roles',\n"," 'including',\n"," 'attempt',\n"," 'chance',\n"," 'wonder',\n"," 'hell',\n"," 'living',\n"," 'happens',\n"," 'violence',\n"," 'told',\n"," 'obvious',\n"," 'happened',\n"," 'coming',\n"," 'involved',\n"," 'voice',\n"," 'save',\n"," 'anyway',\n"," 'score',\n"," 'group',\n"," 'murder',\n"," 'interest',\n"," 'etc',\n"," 'none',\n"," 'gore',\n"," 'serious',\n"," 'looked',\n"," 'type',\n"," 'itbr',\n"," 'alone',\n"," 'daughter',\n"," 'please',\n"," 'happen',\n"," 'exactly',\n"," 'ago',\n"," 'number',\n"," 'god',\n"," 'simple',\n"," 'hours',\n"," 'complete',\n"," 'usually',\n"," 'stop',\n"," 'cinematography',\n"," 'ok',\n"," 'lets',\n"," 'slow',\n"," 'age',\n"," 'whose',\n"," 'sad',\n"," 'musical',\n"," 'shown',\n"," 'known',\n"," 'across',\n"," 'experience',\n"," 'usual',\n"," 'wish',\n"," 'possible',\n"," 'huge',\n"," 'annoying',\n"," 'seriously',\n"," 'finds',\n"," 'david',\n"," 'somewhat',\n"," 'opening',\n"," 'change',\n"," 'song',\n"," 'jokes',\n"," 'female',\n"," 'running',\n"," 'hit',\n"," '4',\n"," 'ends',\n"," 'major',\n"," 'cool',\n"," 'taken',\n"," 'career',\n"," 'taking',\n"," 'scary',\n"," 'hilarious',\n"," 'ridiculous',\n"," 'relationship',\n"," 'crap',\n"," 'released',\n"," 'yourself',\n"," 'started',\n"," 'cut',\n"," 'order',\n"," 'documentary',\n"," 'brother',\n"," 'today',\n"," 'novel',\n"," 'episodes',\n"," 'strange',\n"," 'shots',\n"," 'saying',\n"," 'level',\n"," 'room',\n"," 'supporting',\n"," 'hero',\n"," 'view',\n"," 'robert',\n"," 'knew',\n"," 'english',\n"," 'king',\n"," 'power',\n"," 'songs',\n"," 'british',\n"," 'clearly',\n"," 'attention',\n"," 'mostly',\n"," 'talking',\n"," 'talent',\n"," 'due',\n"," 'happy',\n"," 'important',\n"," 'events',\n"," 'call',\n"," 'turned',\n"," 'opinion',\n"," 'directors',\n"," 'basically',\n"," 'easily',\n"," 'reality',\n"," 'local',\n"," 'knows',\n"," 'husband',\n"," 'apparently',\n"," 'modern',\n"," 'word',\n"," 'upon',\n"," 'words',\n"," 'moviebr',\n"," 'jack',\n"," 'four',\n"," 'single',\n"," '5',\n"," 'arent',\n"," 'body',\n"," 'rating',\n"," 'tells',\n"," 'similar',\n"," 'sequence',\n"," 'bring',\n"," 'future',\n"," 'cheap',\n"," 'entertainment',\n"," 'comic',\n"," 'whether',\n"," 'sets',\n"," 'problems',\n"," 'light',\n"," 'whats',\n"," 'earth',\n"," 'beyond',\n"," 'silly',\n"," 'falls',\n"," 'country',\n"," 'within',\n"," 'television',\n"," 'romantic',\n"," 'disappointed',\n"," 'appears',\n"," 'needs',\n"," 'viewers',\n"," 'mention',\n"," 'giving',\n"," 'storyline',\n"," 'predictable',\n"," 'five',\n"," 'miss',\n"," 'feels',\n"," 'fantastic',\n"," 'paul',\n"," 'george',\n"," 'enjoyable',\n"," 'bunch',\n"," 'talk',\n"," 'review',\n"," 'filmbr',\n"," 'richard',\n"," 'message',\n"," 'thriller',\n"," 'using',\n"," 'theater',\n"," 'nearly',\n"," 'herself',\n"," 'begins',\n"," 'animation',\n"," 'havent',\n"," 'moving',\n"," 'lots',\n"," 'actual',\n"," 'elements',\n"," 'middle',\n"," 'dull',\n"," 'theme',\n"," 'named',\n"," 'add',\n"," 'ways',\n"," 'certain',\n"," 'writer',\n"," 'among',\n"," 'near',\n"," 'lady',\n"," 'tried',\n"," 'peter',\n"," 'stay',\n"," 'showing',\n"," 'surprised',\n"," 'rock',\n"," 'comments',\n"," 'means',\n"," 'typical',\n"," 'general',\n"," 'soundtrack',\n"," 'mystery',\n"," 'class',\n"," 'team',\n"," 'above',\n"," 'sorry',\n"," 'brought',\n"," 'ten',\n"," 'greatest',\n"," 'sequel',\n"," 'effort',\n"," 'famous',\n"," 'release',\n"," 'fall',\n"," 'parents',\n"," 'hate',\n"," 'clear',\n"," 'working',\n"," 'points',\n"," 'doubt',\n"," 'york',\n"," 'easy',\n"," 'avoid',\n"," 'straight',\n"," 'figure',\n"," 'leads',\n"," 'weak',\n"," 'sister',\n"," 'red',\n"," 'somehow',\n"," 'kept',\n"," 'dialog',\n"," 'particular',\n"," 'editing',\n"," 'whos',\n"," 'buy',\n"," 'lame',\n"," 'feature',\n"," 'oscar',\n"," 'tale',\n"," 'realistic',\n"," 'filmed',\n"," 'lee',\n"," 'gone',\n"," 'french',\n"," 'tom',\n"," 'decided',\n"," 'season',\n"," 'hear',\n"," 'viewing',\n"," 'sequences',\n"," 'form',\n"," 'imagine',\n"," 'atmosphere',\n"," 'stand',\n"," 'check',\n"," 'nor',\n"," 'zombie',\n"," 'youve',\n"," 'reviews',\n"," 'period',\n"," 'material',\n"," 'deal',\n"," 'fast',\n"," 'space',\n"," 'learn',\n"," 'surprise',\n"," 'possibly',\n"," 'dance',\n"," 'japanese',\n"," 'follow',\n"," 'move',\n"," 'subject',\n"," 'forget',\n"," 'became',\n"," 'eye',\n"," 'difficult',\n"," 'eventually',\n"," 'sit',\n"," 'crime',\n"," 'whatever',\n"," 'wait',\n"," 'premise',\n"," 'writers',\n"," 'nature',\n"," 'sexual',\n"," 'third',\n"," 'stage',\n"," 'de',\n"," 'leaves',\n"," 'baby',\n"," 'indeed',\n"," 'begin',\n"," '80s',\n"," 'poorly',\n"," 'suspense',\n"," 'die',\n"," 'rent',\n"," 'reading',\n"," 'filmmakers',\n"," 'average',\n"," 'dr',\n"," 'okay',\n"," 'truth',\n"," 'weird',\n"," 'expected',\n"," 'killing',\n"," 'whom',\n"," 'question',\n"," 'meet',\n"," 'street',\n"," 'meets',\n"," 'write',\n"," 'screenplay',\n"," 'forced',\n"," 'disney',\n"," 'unless',\n"," 'note',\n"," 'keeps',\n"," 'believable',\n"," 'needed',\n"," 'dramatic',\n"," 'romance',\n"," 'joe',\n"," 'superb',\n"," 'sounds',\n"," 'memorable',\n"," 'badly',\n"," 'ask',\n"," 'situation',\n"," 'shame',\n"," 'worked',\n"," 'perfectly',\n"," 'older',\n"," 'footage',\n"," 'cheesy',\n"," 'credits',\n"," 'previous',\n"," 'incredibly',\n"," 'features',\n"," 'beauty',\n"," 'otherwise',\n"," 'create',\n"," 'towards',\n"," 'society',\n"," 'realize',\n"," 'earlier',\n"," 'minute',\n"," 'crazy',\n"," 'interested',\n"," 'emotional',\n"," 'effect',\n"," 'boys',\n"," 'free',\n"," 'total',\n"," 'plenty',\n"," 'hot',\n"," 'result',\n"," 'remake',\n"," 'creepy',\n"," 'male',\n"," 'casting',\n"," 'hardly',\n"," 'background',\n"," 'personal',\n"," 'brings',\n"," 'comment',\n"," 'admit',\n"," '20',\n"," 'quickly',\n"," 'open',\n"," 'mark',\n"," 'directing',\n"," 'unique',\n"," 'apart',\n"," 'scifi',\n"," 'return',\n"," 'b',\n"," 'setting',\n"," 'hands',\n"," 'various',\n"," 'leading',\n"," 'laughs',\n"," 'dream',\n"," 'deep',\n"," 'appear',\n"," 'mess',\n"," 'jane',\n"," 'dog',\n"," 'america',\n"," 'plus',\n"," 'fails',\n"," 'portrayed',\n"," 'inside',\n"," 'brothers',\n"," 'meant',\n"," 'development',\n"," 'william',\n"," 'secret',\n"," 'potential',\n"," 'monster',\n"," 'business',\n"," 'ben',\n"," 'imdb',\n"," 'twist',\n"," 'expecting',\n"," 'outside',\n"," 'air',\n"," 'political',\n"," 'deserves',\n"," 'fairly',\n"," 'missing',\n"," 'recently',\n"," 'gay',\n"," 'unlike',\n"," 'powerful',\n"," 'pure',\n"," 'cute',\n"," 'attempts',\n"," 'la',\n"," 'forward',\n"," 'success',\n"," 'ideas',\n"," 'fantasy',\n"," 'box',\n"," 'masterpiece',\n"," 'joke',\n"," 'talented',\n"," ...]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"vuz6-ZwsoMYb"},"source":["**A sequence model built on one-hot encoded vector sequences**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viv1YPX-oMYc","executionInfo":{"status":"ok","timestamp":1698124012243,"user_tz":-300,"elapsed":1021,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"outputId":"e32db0d8-5634-4f74-bb98-cf751e9b0a93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n","                                                                 \n"," bidirectional (Bidirection  (None, 64)                5128448   \n"," al)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5128513 (19.56 MB)\n","Trainable params: 5128513 (19.56 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = tf.one_hot(inputs, depth=max_tokens)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Bidirectional(layers.LSTM(64))(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"1gNk29mLoMYc"},"source":["**Training a first basic sequence model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oD3wXnInoMYc","outputId":"09d4de75-d1f8-49e6-b8f6-7d8f80f5caeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 172s 259ms/step - loss: 0.5496 - accuracy: 0.7229 - val_loss: 0.3957 - val_accuracy: 0.8546\n","Epoch 2/10\n","625/625 [==============================] - 160s 255ms/step - loss: 0.3602 - accuracy: 0.8643 - val_loss: 0.3584 - val_accuracy: 0.8636\n","Epoch 3/10\n","625/625 [==============================] - 162s 258ms/step - loss: 0.2924 - accuracy: 0.8959 - val_loss: 0.3025 - val_accuracy: 0.8752\n","Epoch 4/10\n","625/625 [==============================] - 159s 255ms/step - loss: 0.2494 - accuracy: 0.9161 - val_loss: 0.2767 - val_accuracy: 0.8950\n","Epoch 5/10\n","625/625 [==============================] - 161s 257ms/step - loss: 0.2154 - accuracy: 0.9270 - val_loss: 0.2945 - val_accuracy: 0.8910\n","Epoch 6/10\n","625/625 [==============================] - 161s 257ms/step - loss: 0.1910 - accuracy: 0.9348 - val_loss: 0.2918 - val_accuracy: 0.8850\n","Epoch 7/10\n","120/625 [====>.........................] - ETA: 1:52 - loss: 0.1898 - accuracy: 0.9357"]}],"source":["#callbacks = [\n","#    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n","#                                    save_best_only=True)\n","#]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)\n","#model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"4UpWr_jGoMYd"},"source":["#### Understanding word embeddings"]},{"cell_type":"markdown","metadata":{"id":"cGZSUCBIoMYe"},"source":["#### Learning word embeddings with the Embedding layer"]},{"cell_type":"markdown","metadata":{"id":"AaQa8GwMoMYe"},"source":["**Instantiating an `Embedding` layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8Rpx_7poMYe"},"outputs":[],"source":["embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"]},{"cell_type":"markdown","metadata":{"id":"Ls673IuLoMYe"},"source":["**Model that uses an `Embedding` layer trained from scratch**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuqeSCQzoMYf"},"outputs":[],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","#callbacks = [\n","#    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n","#                                    save_best_only=True)\n","#]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)\n","#model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"-7B25U8ToMYf"},"source":["#### Understanding padding and masking"]},{"cell_type":"markdown","metadata":{"id":"IwPUHX8goMYf"},"source":["**Using an `Embedding` layer with masking enabled**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIXA4P_ioMYf","executionInfo":{"status":"ok","timestamp":1649660714057,"user_tz":-300,"elapsed":1518192,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ba5287b-bf52-4a79-8854-be9428f9b30d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_2 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," bidirectional_2 (Bidirectio  (None, 64)               73984     \n"," nal)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5,194,049\n","Trainable params: 5,194,049\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 149s 223ms/step - loss: 0.3953 - accuracy: 0.8220 - val_loss: 0.2732 - val_accuracy: 0.8864\n","Epoch 2/10\n","625/625 [==============================] - 137s 218ms/step - loss: 0.2255 - accuracy: 0.9121 - val_loss: 0.2655 - val_accuracy: 0.8932\n","Epoch 3/10\n","625/625 [==============================] - 137s 218ms/step - loss: 0.1645 - accuracy: 0.9395 - val_loss: 0.2731 - val_accuracy: 0.8886\n","Epoch 4/10\n","625/625 [==============================] - 136s 217ms/step - loss: 0.1234 - accuracy: 0.9580 - val_loss: 0.3919 - val_accuracy: 0.8704\n","Epoch 5/10\n","625/625 [==============================] - 136s 218ms/step - loss: 0.0949 - accuracy: 0.9669 - val_loss: 0.4077 - val_accuracy: 0.8634\n","Epoch 6/10\n","625/625 [==============================] - 135s 216ms/step - loss: 0.0699 - accuracy: 0.9762 - val_loss: 0.4115 - val_accuracy: 0.8692\n","Epoch 7/10\n","625/625 [==============================] - 135s 216ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.4511 - val_accuracy: 0.8794\n","Epoch 8/10\n","625/625 [==============================] - 136s 217ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.4484 - val_accuracy: 0.8692\n","Epoch 9/10\n","625/625 [==============================] - 135s 217ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.5187 - val_accuracy: 0.8802\n","Epoch 10/10\n","625/625 [==============================] - 136s 217ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.5963 - val_accuracy: 0.8790\n","782/782 [==============================] - 64s 78ms/step - loss: 0.2865 - accuracy: 0.8814\n","Test acc: 0.881\n"]}],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(\n","    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","#callbacks = [\n","#    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n","#                                    save_best_only=True)\n","#]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"FjojXeCkoMYg"},"source":["#### Using pretrained word embeddings"]},{"cell_type":"markdown","source":["A popular pre-trained word embeding is Global Vectors for Word Representation (GloVe,\n","https://nlp.stanford.edu/projects/glove), which was\n","developed by Stanford researchers in 2014. This embedding\n","technique is based on factorizing a matrix of word cooccurrence\n","statistics. Its developers have made available\n","precomputed embeddings for millions of English tokens,\n","obtained from Wikipedia data and Common Crawl data."],"metadata":{"id":"1xGReco1SSv6"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WnLdeYneoMYg","executionInfo":{"status":"ok","timestamp":1758885365774,"user_tz":-300,"elapsed":181732,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f309100-0274-492d-ae55-f338dd418f74"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-09-26 11:13:03--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2025-09-26 11:13:04--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2025-09-26 11:13:04--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n","\n","2025-09-26 11:15:43 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}],"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"]},{"cell_type":"markdown","metadata":{"id":"82OpozNioMYg"},"source":["**Parsing the GloVe word-embeddings file**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-QBUZj7oMYh","executionInfo":{"status":"ok","timestamp":1730781554493,"user_tz":480,"elapsed":6872,"user":{"displayName":"Sher Muhammad Daudpota","userId":"12227288934877670551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de515196-5a6c-4d3b-87c0-6e7e7125708f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}],"source":["import numpy as np\n","path_to_glove_file = \"glove.6B.100d.txt\"\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(f\"Found {len(embeddings_index)} word vectors.\")"]},{"cell_type":"code","source":["print(embeddings_index)"],"metadata":{"id":"Ja-h4aCXnvcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(embeddings_index[\"computer\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDVDFW4qn3kG","executionInfo":{"status":"ok","timestamp":1730781666267,"user_tz":480,"elapsed":602,"user":{"displayName":"Sher Muhammad Daudpota","userId":"12227288934877670551"}},"outputId":"5ddd6a45-bbd1-49ad-a1b8-20acdbaafde7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[-1.6298e-01  3.0141e-01  5.7978e-01  6.6548e-02  4.5835e-01 -1.5329e-01\n","  4.3258e-01 -8.9215e-01  5.7747e-01  3.6375e-01  5.6524e-01 -5.6281e-01\n","  3.5659e-01 -3.6096e-01 -9.9662e-02  5.2753e-01  3.8839e-01  9.6185e-01\n","  1.8841e-01  3.0741e-01 -8.7842e-01 -3.2442e-01  1.1202e+00  7.5126e-02\n","  4.2661e-01 -6.0651e-01 -1.3893e-01  4.7862e-02 -4.5158e-01  9.3723e-02\n","  1.7463e-01  1.0962e+00 -1.0044e+00  6.3889e-02  3.8002e-01  2.1109e-01\n"," -6.6247e-01 -4.0736e-01  8.9442e-01 -6.0974e-01 -1.8577e-01 -1.9913e-01\n"," -6.9226e-01 -3.1806e-01 -7.8565e-01  2.3831e-01  1.2992e-01  8.7721e-02\n","  4.3205e-01 -2.2662e-01  3.1549e-01 -3.1748e-01 -2.4632e-03  1.6615e-01\n","  4.2358e-01 -1.8087e+00 -3.6699e-01  2.3949e-01  2.5458e+00  3.6111e-01\n","  3.9486e-02  4.8607e-01 -3.6974e-01  5.7282e-02 -4.9317e-01  2.2765e-01\n","  7.9966e-01  2.1428e-01  6.9811e-01  1.1262e+00 -1.3526e-01  7.1972e-01\n"," -9.9605e-04 -2.6842e-01 -8.3038e-01  2.1780e-01  3.4355e-01  3.7731e-01\n"," -4.0251e-01  3.3124e-01  1.2576e+00 -2.7196e-01 -8.6093e-01  9.0053e-02\n"," -2.4876e+00  4.5200e-01  6.6945e-01 -5.4648e-01 -1.0324e-01 -1.6979e-01\n","  5.9437e-01  1.1280e+00  7.5755e-01 -5.9160e-02  1.5152e-01 -2.8388e-01\n","  4.9452e-01 -9.1703e-01  9.1289e-01 -3.0927e-01]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0vQoU8eRoMYh"},"source":["**Preparing the GloVe word-embeddings matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JIqivI1oMYh"},"outputs":[],"source":["embedding_dim = 100\n","\n","vocabulary = text_vectorization.get_vocabulary()\n","word_index = dict(zip(vocabulary, range(len(vocabulary))))\n","\n","embedding_matrix = np.zeros((max_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    if i < max_tokens:\n","        embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGQxlsssoMYh"},"outputs":[],"source":["embedding_layer = layers.Embedding(\n","    max_tokens,\n","    embedding_dim,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=False,\n","    mask_zero=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"liuA9kjroMYh"},"source":["**Model that uses a pretrained Embedding layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0GtrfzpoMYh","executionInfo":{"status":"ok","timestamp":1649662813271,"user_tz":-300,"elapsed":1509269,"user":{"displayName":"Sher Muhammad Daudpota","userId":"13684907503251358849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0e3f788e-07d8-4376-c3d4-3ad15812299c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_4 (Embedding)     (None, None, 100)         2000000   \n","                                                                 \n"," bidirectional_3 (Bidirectio  (None, 64)               34048     \n"," nal)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2,034,113\n","Trainable params: 34,113\n","Non-trainable params: 2,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 145s 216ms/step - loss: 0.5762 - accuracy: 0.6929 - val_loss: 0.4626 - val_accuracy: 0.7934\n","Epoch 2/10\n","625/625 [==============================] - 131s 209ms/step - loss: 0.4560 - accuracy: 0.7914 - val_loss: 0.4583 - val_accuracy: 0.7840\n","Epoch 3/10\n","625/625 [==============================] - 131s 210ms/step - loss: 0.4034 - accuracy: 0.8216 - val_loss: 0.3994 - val_accuracy: 0.8224\n","Epoch 4/10\n","625/625 [==============================] - 132s 210ms/step - loss: 0.3719 - accuracy: 0.8400 - val_loss: 0.3594 - val_accuracy: 0.8422\n","Epoch 5/10\n","625/625 [==============================] - 131s 210ms/step - loss: 0.3466 - accuracy: 0.8533 - val_loss: 0.3518 - val_accuracy: 0.8480\n","Epoch 6/10\n","625/625 [==============================] - 131s 210ms/step - loss: 0.3234 - accuracy: 0.8631 - val_loss: 0.3373 - val_accuracy: 0.8586\n","Epoch 7/10\n","625/625 [==============================] - 131s 209ms/step - loss: 0.3074 - accuracy: 0.8736 - val_loss: 0.3204 - val_accuracy: 0.8648\n","Epoch 8/10\n","625/625 [==============================] - 129s 206ms/step - loss: 0.2911 - accuracy: 0.8817 - val_loss: 0.3218 - val_accuracy: 0.8622\n","Epoch 9/10\n","625/625 [==============================] - 129s 206ms/step - loss: 0.2739 - accuracy: 0.8892 - val_loss: 0.3443 - val_accuracy: 0.8498\n","Epoch 10/10\n","625/625 [==============================] - 132s 210ms/step - loss: 0.2610 - accuracy: 0.8945 - val_loss: 0.3128 - val_accuracy: 0.8662\n","782/782 [==============================] - 67s 82ms/step - loss: 0.3057 - accuracy: 0.8686\n","Test acc: 0.869\n"]}],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = embedding_layer(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"oPmg4c-xpr3A"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}